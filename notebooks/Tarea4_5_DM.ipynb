{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902ee99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "               .appName('ml') \\\n",
    "               .getOrCreate()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d197eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"C:/Users/gema2/OneDrive/Escritorio/MAESTRIA/DatosMasivos/data/yellow_tripdata_2025-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c733222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofmonth, date_format, unix_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a3910",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('duracion_viaje',(unix_timestamp(col('tpep_dropoff_datetime'))-unix_timestamp(col('tpep_pickup_datetime')))/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac71c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('RatecodeID','store_and_fwd_flag','PULocationID','DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ba2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('año',year(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a58543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('día',dayofmonth(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2d3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"dia_semana_nombre\", date_format(col(\"tpep_pickup_datetime\"), \"EEEE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a059a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('mes',month(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da166c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio = df.filter((col(\"passenger_count\") > 0) & (col(\"trip_distance\") > 0) & (col(\"total_amount\") > 0) & (col(\"año\") == 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a920cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VendorID: int, tpep_pickup_datetime: timestamp_ntz, tpep_dropoff_datetime: timestamp_ntz, passenger_count: bigint, trip_distance: double, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, Airport_fee: double, cbd_congestion_fee: double, duracion_viaje: double, año: int, día: int, dia_semana_nombre: string, mes: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpio.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe600b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      " |-- duracion_viaje: double (nullable = true)\n",
      " |-- año: integer (nullable = true)\n",
      " |-- día: integer (nullable = true)\n",
      " |-- dia_semana_nombre: string (nullable = true)\n",
      " |-- mes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_limpio.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feff1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calculado = df_limpio.withColumn(\"fare_per_mile\", col(\"fare_amount\") / col(\"trip_distance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07325998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8aa0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+--------------+----+---+-----------------+---+-------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|duracion_viaje| año|día|dia_semana_nombre|mes|fare_per_mile|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+--------------+----+---+-----------------+---+-------------+\n",
      "|       1| 2025-01-01 00:18:38|  2025-01-01 00:26:59|              1|          1.6|           1|       10.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        18.0|                 2.5|        0.0|               0.0|          8.35|2025|  1|        Wednesday|  1|         6.25|\n",
      "|       1| 2025-01-01 00:32:40|  2025-01-01 00:35:13|              1|          0.5|           1|        5.1|  3.5|    0.5|      2.02|         0.0|                  1.0|       12.12|                 2.5|        0.0|               0.0|          2.55|2025|  1|        Wednesday|  1|         10.2|\n",
      "|       1| 2025-01-01 00:44:04|  2025-01-01 00:46:01|              1|          0.6|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|               0.0|          1.95|2025|  1|        Wednesday|  1|          8.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+--------------+----+---+-----------------+---+-------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "df_calculado.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c1255",
   "metadata": {},
   "source": [
    "## Spark MLlib\n",
    "Spark MLlib requiere que todas las características (features) estén agrupadas en una sola columna de tipo vector.\n",
    "Se usará Regresión Lineal para predecir el costo del viaje (fare_amount)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ef1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e1c07",
   "metadata": {},
   "source": [
    "#### Preparación de características\n",
    "Indexar → Vectorizar → Escalar → Seleccionar → Entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90b95252",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"dia_semana_nombre\", outputCol=\"dia_index\")\n",
    "df_ml = indexer.fit(df_limpio).transform(df_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5818fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setInputCols(['trip_distance', 'dia_index','passenger_count']).setOutputCol(\"vector_unificado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6e67cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"vector_unificado\", outputCol=\"features_scaled\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a176b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "798258ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnivariateFeatureSelector_d61f27c617d3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = UnivariateFeatureSelector(featuresCol=\"features_scaled\", labelCol=\"fare_amount\", outputCol=\"selectedFeatures\")\n",
    "selector.setFeatureType(\"continuous\").setLabelType(\"continuous\").setSelectionThreshold(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fb66a",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34eda716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e275b8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado con éxito.\n",
      "Error promedio (RMSE): $17.3\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features_scaled\", labelCol=\"fare_amount\")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, assembler, scaler, selector, lr])\n",
    "\n",
    "train, test = df_limpio.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\", metricName=\"rmse\")  \n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Modelo entrenado con éxito.\")\n",
    "print(f\"Error promedio (RMSE): ${round(rmse, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b17d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices elegidos: [0, 1]\n",
      "Las 2 variables con mayor impacto en el precio son: ['trip_distance', 'dia_index']\n"
     ]
    }
   ],
   "source": [
    "selector_model = model.stages[3]\n",
    "\n",
    "indices_seleccionados = selector_model.selectedFeatures\n",
    "\n",
    "nombres_originales = ['trip_distance', 'dia_index', 'passenger_count']\n",
    "variables_finales = [nombres_originales[i] for i in indices_seleccionados]\n",
    "\n",
    "print(f\"Indices elegidos: {indices_seleccionados}\")\n",
    "print(f\"Las 2 variables con mayor impacto en el precio son: {variables_finales}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
