{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902ee99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Force Spark to use the exact Python executable running this notebook\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Point to your Spark installation\n",
    "os.environ['SPARK_HOME'] = r'C:\\spark'\n",
    "\n",
    "# Windows-specific: Spark needs Hadoop binaries (winutils.exe)\n",
    "# Ensure you have winutils.exe in C:\\hadoop\\bin\n",
    "os.environ['HADOOP_HOME'] = r'C:\\hadoop' \n",
    "os.environ['PATH'] += os.pathsep + r'C:\\hadoop\\bin'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VentasFix\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \n",
    "            \"--add-opens=java.base/java.nio=ALL-UNNAMED \" +\n",
    "            \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \n",
    "            \"--add-opens=java.base/java.nio=ALL-UNNAMED \" +\n",
    "            \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e778ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58113c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_HOME'] = \"C:/hadoop\"\n",
    "os.environ['PATH'] += r\";C:\\hadoop\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f01bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00858f",
   "metadata": {},
   "source": [
    "Trabajar primero en dataframe la limpieza de datos.\n",
    "Es más fácil, los RDDs no se pueden modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d197eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"C:/Users/gema2/OneDrive/Escritorio/MAESTRIA/DatosMasivos/yellow_tripdata_2025-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c733222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofmonth, date_format, unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('duracion_viaje',(unix_timestamp(col('tpep_dropoff_datetime'))-unix_timestamp(col('tpep_pickup_datetime')))/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac71c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('RatecodeID','store_and_fwd_flag','PULocationID','DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ba2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('año',year(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a58543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('día',dayofmonth(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2d3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"dia_semana_nombre\", date_format(col(\"tpep_pickup_datetime\"), \"EEEE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a059a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('mes',month(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da166c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio = df.filter((col(\"passenger_count\") > 0) & (col(\"duracion_viaje\") > 0) & (col(\"total_amount\") > 0) & (col(\"año\") == 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a920cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VendorID: int, tpep_pickup_datetime: timestamp_ntz, tpep_dropoff_datetime: timestamp_ntz, passenger_count: bigint, trip_distance: double, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, Airport_fee: double, cbd_congestion_fee: double, duracion_viaje: double, año: int, día: int, dia_semana_nombre: string, mes: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpio.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50ad66dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2848679"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpio.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df_limpio.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d589b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = df_limpio.select(df_limpio.columns[12]).rdd.flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5f84ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ventas = ventas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596901a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_ventas = ventas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30f8e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de ventas es de: 27.78949766891006\n"
     ]
    }
   ],
   "source": [
    "promedio_ventas = total_ventas / numero_ventas \n",
    "print(f\"Promedio de ventas es de: {promedio_ventas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ff3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 758038, '2': 2966613}\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la cantidad de pasajeros que cada vendor llevó.\n",
    "# VendorID es x[0] y pasajeros es x[3]\n",
    "rdd_parejas = rdd.map(lambda x: (str(x[0]), int(x[3]) if str(x[3]).isdigit() else 0))\n",
    "rdd_sumado = rdd_parejas.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "resultado = rdd_sumado.collect() # collect() devuelve lista de tuplas, suele ser más estable\n",
    "print(dict(resultado))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
